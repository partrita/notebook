{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4e5655-d268-4e5b-8c11-68278b81c20c",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fa0f2f-5977-4d74-a2d1-fe07c3462109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, Wolf built Pixi and had him use that skill to create his own world. In the present day, this has led to him not wanting to return to a land that is devoid of life. Instead, he has gone to\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use GPU (device 0) if available, otherwise fallback to CPU (device -1)\n",
    "generator = pipeline('text-generation', model='gpt2', device=0)\n",
    "\n",
    "# Generate text with a prompt\n",
    "prompt = \"Once upon a time, Wolf built Pixi and\"\n",
    "generated_text = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# Display generated text\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1ba55-46af-4bd6-8c25-98b987ce26cd",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdda59de-c402-4ae0-93f6-3e140aed6f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9952713847160339}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model and use GPU (device=0)\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english', device=0)\n",
    "\n",
    "# Input text for sentiment analysis\n",
    "text = \"I love working with AI models when I can use Pixi!\"\n",
    "\n",
    "# Get sentiment prediction\n",
    "result = classifier(text)\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d30db-2025-46ec-9fbd-04381f7237a6",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545e888b-cff8-4e49-adb2-4c7fd4c0ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pixi is a cross-platform, multi-language package manager and workflow tool built in Rust . Ideal for large-scale data science and machine learning projects, Pixi simplifies environment management while offering flexibility in deployment .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model and use GPU (device=0)\n",
    "summarizer = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6', device=0)\n",
    "\n",
    "# Provide a longer text to summarize\n",
    "text = \"\"\"\n",
    "Pixi is a cross-platform, multi-language package manager and workflow tool built in Rust. Pixi extends Conda with high performance, speed, and reproducibility across languages like Python, C++, and R. Ideal for large-scale data science and machine learning projects, Pixi simplifies environment management while offering flexibility in deployment. It is known for its fast environment resolution times and its ability to handle dependencies across different programming languages in a consistent and efficient way.\n",
    "\"\"\"\n",
    "\n",
    "# Get the summary\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "\n",
    "# Display the summary\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805836f7-4782-410d-92fe-aaba5fe8c9ca",
   "metadata": {},
   "source": [
    "## Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dda0d5-6887-4bdb-9ce9-8b076efd8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'I love learning about AI, machine learning, package management, and Pixi, yo!', 'labels': ['technology', 'entertainment', 'sports'], 'scores': [0.9734852313995361, 0.023062193766236305, 0.00345260719768703]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model and use GPU (device=0)\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli', device=0)\n",
    "\n",
    "# Define input text and candidate labels\n",
    "text = \"I love learning about AI, machine learning, package management, and Pixi, yo!\"\n",
    "candidate_labels = [\"technology\", \"sports\", \"entertainment\"]\n",
    "\n",
    "# Classify text into one of the candidate labels\n",
    "result = classifier(text, candidate_labels)\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629207c8-4974-41b3-a6e3-c94860b73fb7",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fce19a-ad6e-4607-bd0f-cd5156688e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependency hell\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model and use GPU (device=0)\n",
    "qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad', device=0)\n",
    "\n",
    "# Define the context and question\n",
    "context = \"The Pixi library is maintained by Prefix and gets you out of dependency hell!\"\n",
    "question = \"What does Pixi get you out of?\"\n",
    "\n",
    "# Get the answer\n",
    "answer = qa(question=question, context=context)\n",
    "\n",
    "# Display the answer\n",
    "print(answer['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
